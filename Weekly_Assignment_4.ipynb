{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very serious note: Do not use any libraries except for numpy or standard math functions. Implement everything by hand on paper first, this will help you understand the whole process and get some more practice in this week's topic. Then simply code the process in this notebook (you can hard-code, or use any cleaner methodologies. Just make sure that the output is correct). If you are stuck, rewatch the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" alt=\"Neural net cannot be found\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Implement the simple forward pass function and print the final output from the neurons. Error is squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are just helper functions you can use \n",
    "#(feel free to update them and even change the input if you deem it necessary)\n",
    "import numpy as np\n",
    "\n",
    "def SquaredError(target, x):\n",
    "    output = 1/2*((target - x)**2)\n",
    "    return output\n",
    "\n",
    "def Sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def ReLu(x):\n",
    "    output = max(0, x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1_in_function(vx1, vw1, vx2, vw2):\n",
    "    return vx1*vw1+vx2*vw2\n",
    "\n",
    "def o_in_function(vh, vw3, vx3, vw4):\n",
    "    return vh*vw3+vx3*vw4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put your main code here\n",
    "x1, x2, x3 = 5, 7, 2.9\n",
    "w1, w2, w3, w4 = 0.2, 0.4, 0.1, 0.3\n",
    "expected_out = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output from the neuron: 0.7773\n",
      "Squared error: 0.0075\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(v_w1, v_w2, v_w3, v_w4):\n",
    "    v_h1_in =  h1_in_function(x1, v_w1, x2, v_w2)\n",
    "    v_h1_out = ReLu(v_h1_in)\n",
    "\n",
    "    v_o_in = o_in_function(v_h1_out, v_w3, x3, v_w4)\n",
    "    v_o_out = Sigmoid(v_o_in)\n",
    "    return v_o_out\n",
    "\n",
    "o_out = forward_pass(w1, w2, w3, w4)\n",
    "print('Final output from the neuron:', round(o_out, 4))\n",
    "e = SquaredError(expected_out, o_out)\n",
    "print('Squared error:', round(e, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Implement the derivatives of the following (they might be useful later, feel free to change the input variables as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are just helper functions you can use \n",
    "#(feel free to update them and even change the input if you deem it necessary)\n",
    "\n",
    "def SquaredErrorDerivative(target, x):\n",
    "    output = (target - x)*(-1)\n",
    "    return output\n",
    "\n",
    "def SigmoidDerivative(x):\n",
    "    output = x*(1-x)\n",
    "    return output\n",
    "\n",
    "def ReLuDerivative(x):\n",
    "    output = 1 if x>0 else 0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put your main code here\n",
    "def e_w3_derivative():\n",
    "    v_h1_in =  h1_in_function(x1, w1, x2, w2)\n",
    "    v_h1_out = ReLu(v_h1_in)\n",
    "    return v_h1_out\n",
    "\n",
    "def e_w4_derivative():\n",
    "    return x3\n",
    "\n",
    "def e_h1_derivative():\n",
    "    return w3\n",
    "\n",
    "def e_w1_derivative():\n",
    "    return x1\n",
    "\n",
    "def e_w2_derivative():\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Calculate the weight updates via the backward pass. Learning rate alpha is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw: (-0.010619990697652465, -0.01486798697671345, -0.08071192930215873, -0.061595946046384284)\n"
     ]
    }
   ],
   "source": [
    "#put your main code here\n",
    "def backward_pass(v_expected_out, v_o_out):\n",
    "    v_dw3 = SquaredErrorDerivative(v_expected_out, v_o_out) * SigmoidDerivative(v_o_out) * e_w3_derivative()\n",
    "    v_dw4 = SquaredErrorDerivative(v_expected_out, v_o_out) * SigmoidDerivative(v_o_out) * e_w4_derivative()\n",
    "\n",
    "    v_deh1 = SquaredErrorDerivative(v_expected_out, o_out) * SigmoidDerivative(v_o_out) * e_h1_derivative()\n",
    "    v_h1_in = h1_in_function(x1, w1, x2, w2)\n",
    "    v_dw1 = v_deh1 * ReLuDerivative(v_h1_in) * e_w1_derivative()\n",
    "    v_dw2 = v_deh1 * ReLuDerivative(v_h1_in) * e_w2_derivative()\n",
    "    return v_dw1, v_dw2, v_dw3, v_dw4\n",
    "\n",
    "dw = backward_pass(expected_out, o_out)\n",
    "print('dw:', dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Calculate the new weights and update them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1+, w2+, w3+, w4+: 0.20106199906976527 0.40148679869767134 0.10807119293021587 0.30615959460463843\n"
     ]
    }
   ],
   "source": [
    "#put your main code here\n",
    "def updete_weights(v_dw):\n",
    "    a = 0.1\n",
    "    w1x = w1 - a*v_dw[0]\n",
    "    w2x = w2 - a*v_dw[1]\n",
    "    w3x = w3 - a*v_dw[2]\n",
    "    w4x = w4 - a*v_dw[3]\n",
    "    return w1x, w2x, w3x, w4x\n",
    "\n",
    "w1, w2, w3, w4 = updete_weights(dw)\n",
    "print('w1+, w2+, w3+, w4+:', w1, w2, w3, w4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Now do a second forward pass and observe the new output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out after 1 step: 0.7858740215981732\n",
      "Squared error: 0.0065\n"
     ]
    }
   ],
   "source": [
    "#put your main code here\n",
    "o_out = forward_pass(w1, w2, w3, w4)\n",
    "print('out after 1 step:', o_out)\n",
    "e = SquaredError(expected_out, o_out)\n",
    "print('Squared error:', round(e, 4)) \n",
    "\n",
    "# dw = backward_pass(expected_out, o_out)\n",
    "# print('dw:', dw)\n",
    "\n",
    "# w1, w2, w3, w4 = updete_weights(dw)\n",
    "# print('w1+, w2+, w3+, w4+:', w1, w2, w3, w4)\n",
    "\n",
    "# o_out = forward_pass(w1, w2, w3, w4)\n",
    "# print('out after 2 step:', o_out)\n",
    "# e = SquaredError(expected_out, o_out)\n",
    "# print('Squared error:', round(e, 4)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of minor changes in weights, we observe a significant decrease in the Squared error from 0.0075 to 0.0065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
